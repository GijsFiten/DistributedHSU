{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gijsf/Documents/Thesis/2D/data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "datapath = os.getcwd()\n",
    "datasetTrain = 0.7\n",
    "datasetVal = 0.15\n",
    "datasetSize = 10336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training JSON:  4234842\n",
      "Size of the validation JSON:  773435\n",
      "Size of the testing JSON:  663955\n"
     ]
    }
   ],
   "source": [
    "#Load the SunRGB dataset in the coco format\n",
    "NYU40CLASSES = ['void',\n",
    "                'wall', 'floor', 'cabinet', 'bed', 'chair',\n",
    "                'sofa', 'table', 'door', 'window', 'bookshelf',\n",
    "                'picture', 'counter', 'blinds', 'desk', 'shelves',\n",
    "                'curtain', 'dresser', 'pillow', 'mirror', 'floor_mat',\n",
    "                'clothes', 'ceiling', 'books', 'refridgerator', 'television',\n",
    "                'paper', 'towel', 'shower_curtain', 'box', 'whiteboard',\n",
    "                'person', 'night_stand', 'toilet', 'sink', 'lamp',\n",
    "                'bathtub', 'bag', 'otherstructure', 'otherfurniture', 'otherprop'] \n",
    "\n",
    "def arrayFromSUNRGBD_to_coco(pathToData, startIdDataset , stopIdDataset):\n",
    "    coco_dict = {\n",
    "        'images': [],\n",
    "        'annotations': [],\n",
    "        'categories': []\n",
    "    }\n",
    "    category_set = set()\n",
    "    annotation_id = 0\n",
    "    for i in range(startIdDataset, stopIdDataset):\n",
    "        try:\n",
    "            with (open(pathToData + \"/pickles/\" + str(i) + \".pkl\", \"rb\")) as openfile:\n",
    "                dataFromPickle = pickle.load(openfile)\n",
    "                \n",
    "            #Check if the image has no labels\n",
    "            if len(dataFromPickle[\"boxes\"][\"size_cls\"]) == 0:\n",
    "                continue\n",
    "            \n",
    "            #check if all labels are VOID  \n",
    "            if all(label == 0 for label in dataFromPickle[\"boxes\"][\"size_cls\"]):\n",
    "                continue\n",
    "            \n",
    "            image_id = i - startIdDataset\n",
    "            image_info = {\n",
    "                'id': image_id,\n",
    "                'file_name': pathToData + \"/photos/time_data/\" + str(i) + \"/img.jpg\",\n",
    "                # You may need to add 'width' and 'height' fields\n",
    "            }\n",
    "            coco_dict['images'].append(image_info)\n",
    "\n",
    "            boxes = dataFromPickle[\"boxes\"][\"bdb2D_pos\"]\n",
    "            labels = dataFromPickle[\"boxes\"][\"size_cls\"]\n",
    "            for box, label in zip(boxes, labels):\n",
    "                if label == 0:\n",
    "                    continue\n",
    "                \n",
    "                category_set.add(label)\n",
    "                annotation_info = {\n",
    "                    'id': annotation_id,\n",
    "                    'image_id': image_id,\n",
    "                    'category_id': label,  # You may need to map label to category_id\n",
    "                    #data was in xmin, ymin, xmax, ymax format convert to x, y, width, height\n",
    "                    'bbox': [box[0], box[1], int(box[2] - box[0]), int(box[3] - box[1])], \n",
    "                    'area': float(np.abs(box[2] - box[0] * box[3] - box[1])),\n",
    "                    'iscrowd': 0  # Assuming no crowd\n",
    "                }\n",
    "                coco_dict['annotations'].append(annotation_info)\n",
    "                annotation_id += 1\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for category_id, category_name in enumerate(category_set):\n",
    "        category_info = {\n",
    "            'id': category_id,\n",
    "            'name': category_name\n",
    "        }\n",
    "        coco_dict['categories'].append(category_info)\n",
    "\n",
    "    return coco_dict\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NumpyEncoder, self).default(obj)\n",
    "        \n",
    "# Convert the dataset to a dictionary in the COCO format\n",
    "coco_dict = arrayFromSUNRGBD_to_coco(datapath,1,int(datasetSize*datasetTrain))\n",
    "with open('coco_dataset_train.json', 'w') as f:\n",
    "    json.dump(coco_dict, f, cls=NumpyEncoder)\n",
    "    print(\"Size of the training JSON: \", f.tell())\n",
    "\n",
    "coco_dict = arrayFromSUNRGBD_to_coco(datapath,int(datasetSize*datasetTrain),int((datasetTrain+datasetVal)*datasetSize))\n",
    "with open('coco_dataset_val.json', 'w') as f:\n",
    "    json.dump(coco_dict, f, cls=NumpyEncoder)\n",
    "    print(\"Size of the validation JSON: \", f.tell())\n",
    "\n",
    "coco_dict = arrayFromSUNRGBD_to_coco(datapath,int((datasetTrain+datasetVal)*datasetSize),datasetSize)\n",
    "with open('coco_dataset_test.json', 'w') as f:\n",
    "    json.dump(coco_dict, f, cls=NumpyEncoder)\n",
    "    print(\"Size of the testing JSON: \", f.tell())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detrex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
